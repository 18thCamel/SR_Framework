#generate settings
mode: SR
#use_cl: true
gpu_ids: [3]

scale: 2
patch_size: 128

#datasets
datasets:
  train:
    mode: LRHR
    dataroot_HR: ../agora_train/train/HR
    dataroot_LR: ../agora_train/train/LR
    filename_path: ../agora_train/train/train.txt
    n_workers: 4
    batch_size: 16
    use_flip: true
    use_rot: true
    noise: ~
  val:
    mode: LRHR
    dataroot_HR: ../agora_train/train/HR
    dataroot_LR: ../agora_train/train/LR
    filename_path: ../agora_train/train/val.txt
    noise: ~

#networks
networks:
  which_model: baseline
  in_channels: 3
  num_fea: 12
  out_channels: 3
  dataparallel: false
      
#path to save
paths:
  experiment_root: ./experiment
  root: ~ # determined by model_name
  epochs: ~ 
  visual: ~ 
  records: ~

#optimizer
solver:
  type: ADAM
  init_type: kaiming
  learning_rate: !!float 1e-3
  weight_decay: 0
  lr_scheme: MultiStepLR
  lr_steps: 
    - 200
    - 400
    - 600
    - 800
  lr_gamma: !!float 0.5
  loss_type: l1
  manual_seed: 0
  num_epochs: 1000
  skip_threshold: 3
  #split_batch: 2
  save_vis_step: 50 
  val_step: 50
  pretrained: ~
  #../SRFBN_CVPR19/models/SRFBN_x2_BI.pth
  cl_weights: [1.0, 1.0, 1.0, 1.0]

#print
print:
  print_freq: 10
